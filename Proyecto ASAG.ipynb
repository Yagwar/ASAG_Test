{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Artificial Neural Network for Automatic Short Answer Grading\n",
    "Automatic Short Answer Grading (ASAG) is the task of implementing a system that automatically assigns a class value related to the quality of an short-answer question (correct - incorrect). The aim of this project is to take a question from the ScientistBank dataset for train an Artifical Neural Network (ANN) that clasifies the answers of the students. The architecture is based on the model of  [Alikaniotis(2016)](https://arxiv.org/abs/1606.04289)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estructura trabajo\n",
    "## Planteamiento proyecto\n",
    "Redes neuronales para calificación automática de respuestas cortas\n",
    "## Diseño experimental con diferntes parámetros (variable independiente factor)\n",
    "Valores de variable independiente por factores: cada setup experimental es una forma de la variable independiente\n",
    "\n",
    "- Entrenar word embeddings\n",
    "- Comenzar con un perceptrón y terminar con una red LSTM (mirar otras arquitecturas posibles)\n",
    "- Combinar otros métodos (SVM...)\n",
    "\n",
    "## Definir medida de desempeño (variable dependiente)\n",
    "AUC(ROC),Concordancias entre jueces, coeficientes de correlación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import xml.etree.ElementTree as ET\n",
    "#import sswe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import theano\n",
    "#import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# ASOBEK Embeddings\n",
    "#from nltk.tokenize import word_tokenize\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn import cross_validation\n",
    "import re\n",
    "#from nltk.util import ngrams\n",
    "from collections import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('PS-inv1-2a_ScientisTrain.xml')\n",
    "root = tree.getroot()\n",
    "question=root[0].text\n",
    "grade=[branch.attrib[\"accuracy\"] for branch in root[2]]\n",
    "answers_st=[branch.text for branch in root[2]]\n",
    "answers_ref=[branch.text for branch in root[1]]### If there are more of 1 reference answer it will give an array of an answers. Make sure you integrate it before processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "califs=[1 if resp==\"correct\" else 0 for resp in grade]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why does a rubber band make a sound when you pluck it (pull and let go quickly)?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The rubber band vibrates.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(answers_st)\n",
    "anwsr_refArry=[answers_ref[0] for answer in answers_st]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respuesta</th>\n",
       "      <th>Calif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Because it is sticky!</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Because it hits the other side.</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because vibration.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It makes the plucking sound from stretching an...</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Because if you stretch it and let it go it mak...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Plucking is pull.</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Because it hits the other part of the rubber b...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Because it vibrates.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Because your making vibrations.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Because it vibrates.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Because the vibrations.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Because it is tight.</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Because it is vibrating.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vibrations.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The rubber band makes a sound because it is on...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Respuesta      Calif\n",
       "0                               Because it is sticky!  incorrect\n",
       "1                     Because it hits the other side.  incorrect\n",
       "2                                  Because vibration.    correct\n",
       "3   It makes the plucking sound from stretching an...    correct\n",
       "4   Because if you stretch it and let it go it mak...  incorrect\n",
       "5                                   Plucking is pull.  incorrect\n",
       "6   Because it hits the other part of the rubber b...  incorrect\n",
       "7                                Because it vibrates.    correct\n",
       "8                     Because your making vibrations.    correct\n",
       "9                                Because it vibrates.    correct\n",
       "10                            Because the vibrations.    correct\n",
       "11                               Because it is tight.  incorrect\n",
       "12                           Because it is vibrating.    correct\n",
       "13                                        Vibrations.    correct\n",
       "14  The rubber band makes a sound because it is on...  incorrect"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.column_stack([answers_st,grade]),columns=[\"Respuesta\",\"Calif\"])[:15]\n",
    "#answers_st[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- stemming\n",
    "- tolower\n",
    "- tf-idf(opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://www.nltk.org/book/ch03.html\n",
    "- https://de.dariah.eu/tatom/preprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Query expantion\n",
    "wordnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline methods\n",
    "- wordcount con word2vec (preentrenado google news)\n",
    "- ASOBEK\n",
    "- c&w (???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named gensim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-22ac541fe790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named gensim"
     ]
    }
   ],
   "source": [
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3f0de3ca3ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%(asctime)s : %(levelname)s : %(message)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers_st\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = gensim.models.Word2Vec(answers_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gensim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c40c454812cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# an empty model, no training yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers_st\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# can be a non-repeatable, 1-pass generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers_st\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# can be a non-repeatable, 1-pass generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gensim' is not defined"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(iter=1)  # an empty model, no training yet\n",
    "model.build_vocab(answers_st)  # can be a non-repeatable, 1-pass generator\n",
    "model.train(answers_st)  # can be a non-repeatable, 1-pass generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASOBEK Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASOBEK feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_asobek(dataA, dataB):\n",
    "    '''\n",
    "    Takes the paraphrases and returns the asobek features ## (Array de respuestas)\n",
    "    \n",
    "    Arguments\n",
    "    --\n",
    "    dataA: List containing the source sentences of paraphrasing\n",
    "    dataB: List containing the candidate sentences of paraphrasing\n",
    "    \n",
    "    Returns\n",
    "    --\n",
    "    [Unigram word features, Bigram word features, Unigram character features, Bigram character features]\n",
    "    '''\n",
    "    if len(dataA) != len(dataB):\n",
    "        print 'Check length of your data'\n",
    "        return\n",
    "    features = []\n",
    "    def get_cardinalities(ngramA, ngramB):\n",
    "        vector = []\n",
    "        vector.append(union(ngramA, ngramB))\n",
    "        vector.append(intersect(ngramA, ngramB))\n",
    "        vector.append(set(ngramA))\n",
    "        vector.append(set(ngramB))\n",
    "        return vector\n",
    "    \n",
    "    for x in np.arange(len(dataA)):\n",
    "        unigram_1 = get_wordngram(dataA[x],1)\n",
    "        unigram_2 = get_wordngram(dataB[x],1)\n",
    "        bigram_1 = get_wordngram(dataA[x],2)\n",
    "        bigram_2 = get_wordngram(dataB[x],2)\n",
    "        unigram_c_1 = get_characterngram(dataA[x],1)\n",
    "        unigram_c_2 = get_characterngram(dataB[x],1)\n",
    "        bigram_c_1 = get_characterngram(dataA[x],2)\n",
    "        bigram_c_2 = get_characterngram(dataB[x],2)\n",
    "        w1 = [len(x) for x in get_cardinalities(unigram_1, unigram_2)]\n",
    "        w2 = [len(x) for x in get_cardinalities(bigram_1, bigram_2)]\n",
    "        c1 = [len(x) for x in get_cardinalities(unigram_c_1, unigram_c_2)]\n",
    "        c2 = [len(x) for x in get_cardinalities(bigram_c_1, bigram_c_2)]\n",
    "        features.append([w1, w2, c1, c2])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are some helpers for encode_asobek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def union(list1, list2):\n",
    "    cnt1 = Counter()\n",
    "    cnt2 = Counter()\n",
    "    for tk1 in list1:\n",
    "        cnt1[tk1] += 1\n",
    "    for tk2 in list2:\n",
    "        cnt2[tk2] += 1\n",
    "    inter = cnt1 | cnt2\n",
    "    return set(inter.elements())\n",
    "def intersect (list1, list2) :\n",
    "    cnt1 = Counter()\n",
    "    cnt2 = Counter()\n",
    "    for tk1 in list1:\n",
    "        cnt1[tk1] += 1\n",
    "    for tk2 in list2:\n",
    "        cnt2[tk2] += 1\n",
    "    inter = cnt1 & cnt2\n",
    "    return list(inter.elements())\n",
    "\n",
    "def get_characterngram(string, n):\n",
    "    '''Returns n-grams of characters'''\n",
    "    char1 = [c for c in string]\n",
    "    return list(ngrams(char1, n))\n",
    "\n",
    "def get_wordngram(string, n):\n",
    "    '''Returns n-grams of words'''\n",
    "    words = word_tokenize(string)\n",
    "    return list(ngrams(words, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elaborate ASOBEK features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-23b2c00ba69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#decode(\"utf-8\") is really important\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Preprocessing: Only lowercase all the words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manwsr_refArry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# Respuesta referencia - Tantas como rtas de estudiantes hayan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdataB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manswers_st\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# Respuesta estudiantes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_asobek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "dataA, dataB = [], []\n",
    "#decode(\"utf-8\") is really important\n",
    "#Preprocessing: Only lowercase all the words\n",
    "dataA = [' '.join(word_tokenize(x.decode(\"utf-8\").lower())) for x in anwsr_refArry]# Respuesta referencia - Tantas como rtas de estudiantes hayan\n",
    "dataB = [' '.join(word_tokenize(x.decode(\"utf-8\").lower())) for x in answers_st]# Respuesta estudiantes\n",
    "X_train = encode_asobek(dataA, dataB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keras tokenizer\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b3d1c13e4676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manwsr_refArry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#dataA = [keras.preprocessing.text.Tokenizer(text=x) for x in anwsr_refArry]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "keras.preprocessing.text.Tokenizer(anwsr_refArry[0])\n",
    "#dataA = [keras.preprocessing.text.Tokenizer(text=x) for x in anwsr_refArry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3327c0882c17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'I love you.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'I love you, too.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "tk = keras.preprocessing.text.Tokenizer()\n",
    "texts = ['I love you.', 'I love you, too.']\n",
    "tk.fit_on_texts(texts)\n",
    "tk.texts_to_matrix(texts, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for clasification\n",
    "### Long-short term memory network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
