{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Artificial Neural Network for Automatic Short Answer Grading\n",
    "Automatic Short Answer Grading (ASAG) is the task of implementing a system that automatically assigns a class value related to the quality of an short-answer question (correct - incorrect). The aim of this project is to take a question from the ScientistBank dataset for train an Artifical Neural Network (ANN) that clasifies the answers of the students. The architecture is based on the model of  [Alikaniotis(2016)](https://arxiv.org/abs/1606.04289)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estructura trabajo\n",
    "## Planteamiento proyecto\n",
    "Redes neuronales para calificación automática de respuestas cortas\n",
    "## Diseño experimental con diferntes parámetros (variable independiente factor)\n",
    "Valores de variable independiente por factores: cada setup experimental es una forma de la variable independiente\n",
    "\n",
    "- Entrenar word embeddings\n",
    "- Comenzar con un perceptrón y terminar con una red LSTM (mirar otras arquitecturas posibles)\n",
    "- Combinar otros métodos (SVM...)\n",
    "\n",
    "## Definir medida de desempeño (variable dependiente)\n",
    "AUC(ROC),Concordancias entre jueces, coeficientes de correlación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import xml.etree.ElementTree as ET\n",
    "import sswe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import theano\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Embeddings\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn import cross_validation\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "from collections import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# Clasifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "# LSTM \n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('PS-inv1-2a_ScientisTrain.xml')\n",
    "root = tree.getroot()\n",
    "question=root[0].text\n",
    "grade=[branch.attrib[\"accuracy\"] for branch in root[2]]\n",
    "answers_st=[branch.text for branch in root[2]]\n",
    "answers_ref=[branch.text for branch in root[1]]### If there are more of 1 reference answer it will give an array of an answers. Make sure you integrate it before processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "califs=[1 if resp==\"correct\" else 0 for resp in grade]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why does a rubber band make a sound when you pluck it (pull and let go quickly)?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The rubber band vibrates.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(answers_st)\n",
    "anwsr_refArry=[answers_ref[0] for answer in answers_st]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respuesta</th>\n",
       "      <th>Calif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Because it is sticky!</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Because it hits the other side.</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because vibration.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It makes the plucking sound from stretching an...</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Because if you stretch it and let it go it mak...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Plucking is pull.</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Because it hits the other part of the rubber b...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Because it vibrates.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Because your making vibrations.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Because it vibrates.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Because the vibrations.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Because it is tight.</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Because it is vibrating.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vibrations.</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The rubber band makes a sound because it is on...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Respuesta      Calif\n",
       "0                               Because it is sticky!  incorrect\n",
       "1                     Because it hits the other side.  incorrect\n",
       "2                                  Because vibration.    correct\n",
       "3   It makes the plucking sound from stretching an...    correct\n",
       "4   Because if you stretch it and let it go it mak...  incorrect\n",
       "5                                   Plucking is pull.  incorrect\n",
       "6   Because it hits the other part of the rubber b...  incorrect\n",
       "7                                Because it vibrates.    correct\n",
       "8                     Because your making vibrations.    correct\n",
       "9                                Because it vibrates.    correct\n",
       "10                            Because the vibrations.    correct\n",
       "11                               Because it is tight.  incorrect\n",
       "12                           Because it is vibrating.    correct\n",
       "13                                        Vibrations.    correct\n",
       "14  The rubber band makes a sound because it is on...  incorrect"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.column_stack([answers_st,grade]),columns=[\"Respuesta\",\"Calif\"])[:15]\n",
    "#answers_st[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- stemming\n",
    "- tolower\n",
    "- tf-idf(opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://www.nltk.org/book/ch03.html\n",
    "- https://de.dariah.eu/tatom/preprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Query expantion\n",
    "wordnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline methods\n",
    "- wordcount con word2vec (preentrenado google news)\n",
    "- ASOBEK\n",
    "- c&w (???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = gensim.models.Word2Vec(answers_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(iter=1)  # an empty model, no training yet\n",
    "model.build_vocab(answers_st)  # can be a non-repeatable, 1-pass generator\n",
    "w2v_emb=model.train(answers_st)  # can be a non-repeatable, 1-pass generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASOBEK Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASOBEK feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_asobek(dataA, dataB):\n",
    "    '''\n",
    "    Takes the paraphrases and returns the asobek features ## (Array de respuestas)\n",
    "    \n",
    "    Arguments\n",
    "    --\n",
    "    dataA: List containing the source sentences of paraphrasing\n",
    "    dataB: List containing the candidate sentences of paraphrasing\n",
    "    \n",
    "    Returns\n",
    "    --\n",
    "    [Unigram word features, Bigram word features, Unigram character features, Bigram character features]\n",
    "    '''\n",
    "    if len(dataA) != len(dataB):\n",
    "        print ('Check length of your data')\n",
    "        return\n",
    "    features = []\n",
    "    def get_cardinalities(ngramA, ngramB):\n",
    "        vector = []\n",
    "        vector.append(union(ngramA, ngramB))\n",
    "        vector.append(intersect(ngramA, ngramB))\n",
    "        vector.append(set(ngramA))\n",
    "        vector.append(set(ngramB))\n",
    "        return vector\n",
    "    \n",
    "    for x in np.arange(len(dataA)):\n",
    "        unigram_1 = get_wordngram(dataA[x],1)\n",
    "        unigram_2 = get_wordngram(dataB[x],1)\n",
    "        bigram_1 = get_wordngram(dataA[x],2)\n",
    "        bigram_2 = get_wordngram(dataB[x],2)\n",
    "        unigram_c_1 = get_characterngram(dataA[x],1)\n",
    "        unigram_c_2 = get_characterngram(dataB[x],1)\n",
    "        bigram_c_1 = get_characterngram(dataA[x],2)\n",
    "        bigram_c_2 = get_characterngram(dataB[x],2)\n",
    "        w1 = [len(x) for x in get_cardinalities(unigram_1, unigram_2)]\n",
    "        w2 = [len(x) for x in get_cardinalities(bigram_1, bigram_2)]\n",
    "        c1 = [len(x) for x in get_cardinalities(unigram_c_1, unigram_c_2)]\n",
    "        c2 = [len(x) for x in get_cardinalities(bigram_c_1, bigram_c_2)]\n",
    "        features.append([w1, w2, c1, c2])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are some helpers for encode_asobek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def union(list1, list2):\n",
    "    cnt1 = Counter()\n",
    "    cnt2 = Counter()\n",
    "    for tk1 in list1:\n",
    "        cnt1[tk1] += 1\n",
    "    for tk2 in list2:\n",
    "        cnt2[tk2] += 1\n",
    "    inter = cnt1 | cnt2\n",
    "    return set(inter.elements())\n",
    "def intersect (list1, list2) :\n",
    "    cnt1 = Counter()\n",
    "    cnt2 = Counter()\n",
    "    for tk1 in list1:\n",
    "        cnt1[tk1] += 1\n",
    "    for tk2 in list2:\n",
    "        cnt2[tk2] += 1\n",
    "    inter = cnt1 & cnt2\n",
    "    return list(inter.elements())\n",
    "\n",
    "def get_characterngram(string, n):\n",
    "    '''Returns n-grams of characters'''\n",
    "    char1 = [c for c in string]\n",
    "    return list(ngrams(char1, n))\n",
    "\n",
    "def get_wordngram(string, n):\n",
    "    '''Returns n-grams of words'''\n",
    "    words = word_tokenize(string)\n",
    "    return list(ngrams(words, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elaborate ASOBEK features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataA, dataB = [], []\n",
    "#decode(\"utf-8\") is really important\n",
    "#Preprocessing: Only lowercase all the words\n",
    "dataA = [' '.join(word_tokenize(x.decode(\"utf-8\").lower())) for x in anwsr_refArry]# Respuesta referencia - Tantas como rtas de estudiantes hayan\n",
    "dataB = [' '.join(word_tokenize(x.decode(\"utf-8\").lower())) for x in answers_st]# Respuesta estudiantes\n",
    "X_train = encode_asobek(dataA, dataB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[0]\n",
    "\n",
    "c1w2train = np.array([x[2]+x[1] for x in X_train])#Here the index indicates the position w1=0, w2=1, c1=2, c2=3\n",
    "w1w2train = np.array([x[0]+x[1] for x in X_train])\n",
    "c1c2train = np.array([x[2]+x[3] for x in X_train])\n",
    "w2c2train = np.array([x[1]+x[3] for x in X_train])\n",
    "\n",
    "training_combinations=[c1w2train, w1w2train, c1c2train, w2c2train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Test accuracy: 0.769230769231\n",
      "Test F1: 0.75\n",
      "Test accuracy: 0.644230769231\n",
      "Test F1: 0.564705882353\n",
      "Test accuracy: 0.836538461538\n",
      "Test F1: 0.828282828283\n",
      "Test accuracy: 0.903846153846\n",
      "Test F1: 0.901960784314\n"
     ]
    }
   ],
   "source": [
    "print ('Evaluating...')\n",
    "scaling = True\n",
    "for i in range(len(training_combinations)):\n",
    "    clf = LogisticRegression(C=1)\n",
    "    if scaling:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(training_combinations[i])\n",
    "        clf.fit(X, califs)\n",
    "        X_test = scaler.transform(training_combinations[i])\n",
    "    else:\n",
    "        clf.fit(training_combinations[i],califs)\n",
    "        X_test = training_combinations[i]\n",
    "    yhat = clf.predict(X_test)\n",
    "    print ('Test accuracy: ' + str(clf.score(X_test,califs)))\n",
    "    print ('Test F1: ' + str(f1(califs, yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic 0.903846153846\n",
      "Naive Bayes 0.730769230769\n",
      "Support Vector Lineal Classificator 0.865384615385\n",
      "Random Forest 1.0\n"
     ]
    }
   ],
   "source": [
    "X_train = w2c2train\n",
    "X_test = w2c2train\n",
    "y_train = califs\n",
    "y_test = califs\n",
    "\n",
    "# Create classifiers\n",
    "lr = LogisticRegression()\n",
    "gnb = GaussianNB()\n",
    "svc = LinearSVC(C=1.0)\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "for clf, name in [(lr, 'Logistic'),\n",
    "                  (gnb, 'Naive Bayes'),\n",
    "                  (svc, 'Support Vector Lineal Classificator'),\n",
    "                  (rfc, 'Random Forest')]:\n",
    "    clf.fit(X_train, y_train)\n",
    "    print (name,clf.score(X_test,califs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "training_combination 0\n",
      "Logistic 0.769230769231\n",
      "Test F1: 0.75\n",
      "training_combination 0\n",
      "Naive Bayes 0.798076923077\n",
      "Test F1: 0.774193548387\n",
      "training_combination 0\n",
      "Support Vector Lineal Classificator 0.759615384615\n",
      "Test F1: 0.747474747475\n",
      "training_combination 0\n",
      "Random Forest 0.990384615385\n",
      "Test F1: 0.989898989899\n",
      "training_combination 1\n",
      "Logistic 0.644230769231\n",
      "Test F1: 0.564705882353\n",
      "training_combination 1\n",
      "Naive Bayes 0.625\n",
      "Test F1: 0.541176470588\n",
      "training_combination 1\n",
      "Support Vector Lineal Classificator 0.653846153846\n",
      "Test F1: 0.581395348837\n",
      "training_combination 1\n",
      "Random Forest 0.807692307692\n",
      "Test F1: 0.811320754717\n",
      "training_combination 2\n",
      "Logistic 0.836538461538\n",
      "Test F1: 0.828282828283\n",
      "training_combination 2\n",
      "Naive Bayes 0.798076923077\n",
      "Test F1: 0.792079207921\n",
      "training_combination 2\n",
      "Support Vector Lineal Classificator 0.846153846154\n",
      "Test F1: 0.84\n",
      "training_combination 2\n",
      "Random Forest 1.0\n",
      "Test F1: 1.0\n",
      "training_combination 3\n",
      "Logistic 0.903846153846\n",
      "Test F1: 0.901960784314\n",
      "training_combination 3\n",
      "Naive Bayes 0.730769230769\n",
      "Test F1: 0.681818181818\n",
      "training_combination 3\n",
      "Support Vector Lineal Classificator 0.903846153846\n",
      "Test F1: 0.901960784314\n",
      "training_combination 3\n",
      "Random Forest 1.0\n",
      "Test F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "print ('Evaluating...')\n",
    "scaling = True\n",
    "for i in range(len(training_combinations)):\n",
    "    # Create classifiers\n",
    "    lr = LogisticRegression()\n",
    "    gnb = GaussianNB()\n",
    "    svc = LinearSVC(C=1.0)\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(training_combinations[i])\n",
    "\n",
    "    for clf, name in [(lr, 'Logistic'),\n",
    "                      (gnb, 'Naive Bayes'),\n",
    "                      (svc, 'Support Vector Lineal Classificator'),\n",
    "                      (rfc, 'Random Forest')]:\n",
    "        clf.fit(X, y_train)\n",
    "        yhat = clf.predict(X)\n",
    "        print (\"training_combination\", i)\n",
    "        print (name,clf.score(X,califs))\n",
    "        print ('Test F1: ' + str(f1(califs, yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf for trainning neural network\n",
    "\n",
    "http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "tf_st = vectorizer.fit_transform(answers_st)\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf_st = transformer.fit_transform(tf_st)\n",
    "tfidf_st.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = tfidf_st.toarray()\n",
    "X_test = tfidf_st.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic = Score: 0.980769230769 F1 score: 0.979166666667\n",
      "Naive Bayes = Score: 0.951923076923 F1 score: 0.95145631068\n",
      "Support Vector Lineal Classificator = Score: 1.0 F1 score: 1.0\n",
      "Random Forest = Score: 1.0 F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create classifiers\n",
    "lr = LogisticRegression()\n",
    "gnb = GaussianNB()\n",
    "svc = LinearSVC(C=1.0)\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "for clf, name in [(lr, 'Logistic'),\n",
    "                  (gnb, 'Naive Bayes'),\n",
    "                  (svc, 'Support Vector Lineal Classificator'),\n",
    "                  (rfc, 'Random Forest')]:\n",
    "    clf.fit(X_train, y_train)\n",
    "    yhat = clf.predict(X_train)\n",
    "    print (name, \"= Score:\",clf.score(X_train,califs),\"F1 score:\",f1(califs, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for clasification\n",
    "### Long-short term memory network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 104, 8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(training_combinations).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(w2c2train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
